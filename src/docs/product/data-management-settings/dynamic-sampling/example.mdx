---
title: Example of Sampling Methods
sidebar_order: 40
description: "Review an example of Dynamic Sampling."
---

The following example illustrates when different sampling methods might be useful. In this example, the system is composed of:
- UI clients that are mobile applications running on our clients' phones, which call
- an API backend, which further calls
- services

The system is replicated on multiple servers running differing versions of the software. Two versions of our mobile application, UI-1.1 and UI-1.2, have been released. Not all clients have yet upgraded to the last version (UI-1.2).

A new backend API, release API-2.0, has also been recently released. This API should work with both the new and old clients. However, release API-2.0 has been deployed to only one server, since its performance under production load is not yet known. As a result, servers are running both release API-1.0 and release API-2.0.

Service (S1) is running only on release S1-1.4, and has been stable until now.

![](example-sys-dependency.png)

In the example, four traces (T1..T4) are generated by users. The user running UI 1.1. creates T1 and T2, which go through different API servers. Similarly, the user running UI 1.2 creates T3 and T4. These two traces also go through different API servers. The server running S1 service is reached by all four traces.

The interaction described causes the following transaction events (T) and error events (E) in the system.

|Nr.|System|Type|Tr. Id|Tr. rel.| Tr. ProjId | Ev Id| Ev rel. |Ev ProjId|
|: - :|: - :|: - :|: - :|: - :|: - :|: - :|: - :|: - :|
|1 | UI | T| T1 | UI 1.1 |  p1 | E1 | 1.1 | p1 |
|2 | API | T | T1 | UI 1.1 | p1 | E2  | API-1.0  | p2  |
|3 | S1 | T | T1 | UI 1.1 | p1 | E3 | S1-1.4 | p3 |
|4 | UI | T| T2 | UI 1.1 |  p1 | E4 | 1.1 | p1 |
|5 | API | T | T2 | UI 1.1 | p1 | E5  | API-2.0  | p2  |
|6 | API | E | T2 | UI 1.1 | p1 | E5  | API-2.0  | p2  |
|7 | S1 | T | T2 | UI 1.1 | p1 | E6 | S1-1.4 | p3 |
|8 | UI | T| T3 | UI 1.2 |  p1 | E1 | 1.1 | p1 |
|9 | API | T | T3 | UI 1.2 | p1 | E2  | API-1.0  | p2  |
|10 | S1 | T | T3 | UI 1.2 | p1 | E3 | S1-1.4 | p3 |
|11 | S1 | E | T3 | UI 1.2 | p1 | E3 | S1-1.4 | p3 |
|12 | UI | T| T4 | UI 1.2 |  p1 | E4 | 1.1 | p1 |
|13 | API | T | T4 | UI 1.2 | p1 | E5  | API-2.0  | p2  |
|14 | API | E | T4 | UI 1.2 | p1 | E5  | API-2.0  | p2  |
|15 | S1 | T | T4 | UI 1.2 | p1 | E6 | S1-1.4 | p3 |

In the table above, type T denotes transactions and type E denotes errors.
After releasing the API service version: API-2.0, a regression is introduced.
Each time a call is made to this API, an error generated, as denoted by events 6 and 14.

When releasing a new version of the API, it would be helpful to keep all (or a large portion) of traces to give context to errors. This is where individual transaction rules are extremely useful. To select transactions from API-2.0, you need to base the rules on the event data, since in the trace data you have information only about the trace initiator (the UI).

A more interesting case is the error in event 11, which is an error in the service S1. Server S1 has been working fine for a very long time and the QA team has not found any problem in testing (but the QA team has been testing with only the most recent software UI-1.2 and API 2.0 ). This error appears in the service S1, but only when the calls originate in UI 1.2 and go through an API service at version API 1.0. It suggests that perhaps in version UI 1.2 an additional parameter was introduced that is unknown by API 1.0, since API 1.0 was released before UI 1.2. API 1.0 does not know how to handle the new parameter, so it passes it unprocessed downstream to S1 (likely because of an issue with input validation to the API layer).

Errors that involve interaction among multiple systems running various versions of the software can be frustratingly difficult to understand in the absence of distributed traces. For an error like the one in event 11, you need access to the whole trace to understand what is going on; this is where trace sampling becomes so useful. With trace sampling, the sampling decision is based on the trace state. All transactions within a trace are kept or discarded together, so you can understand the path of the request through the system.
